* Spec
** Model Builder
*** Input: TSV file, Output: GBC predicting model
** predict
*** Input any revisionid, Output: it should predict probability of is_damaging
* Design considerations
** I should be able to build up the model very quickly
*** It will take a lot of time to download the Articles from wikipedia
*** It will take a lot of time to hvtransform the articles
** I should be able to debug with a particular revid
*** debug model builder
*** debug the prediction
* Design/Pseudo Code
process (revids[], typeofdata='training_set' | 'test_set')
 download_and_pickle(revids) if not present in dir(typeofdata)
 launch a thread for hv.transform
   load data
   extract required fields
   transform
   save processed data as pickle

build_model()
 read pickles and construct features matrix
 where do I labels?
 GBC(features_X, labels)

######

download(revids[])
  //save content
  doc.append =  download
  return doc

# download texts, save texts and labels in db
prepare_data_set(revids=null)
  revid, label =  read_tsv()
  doc = download(revids[])
  save_docs(revid, doc, label)

# transform revids, saves the feature vectors in db
transform(revids[])
 texts  = load_texts(revids)
 labels = load_labels(revids)
 features = hv.transform(texts)
 save_features(revids, features)

#
test(revids[])
  features, labels = load_train_set()
  build_model(features, labels)

  features_t, labels_t = load_test_set()
  score(features_t, labels_t)

predict(revid)
  features, labels = load_train_set()
  build_model(features, labels)
  predict()
* Code explained
SCHEMA
observations
    (revid INTEGER PRIMARY KEY,
    other_features TEXT,
    is_damaging INTEGER)

content
    (revid INTEGER PRIMARY KEY,
    revid_parent INTEGER,
    content_current BLOB,
    content_parent BLOB)

feature_vector
    (revid INTEGER PRIMARY KEY,
    current BLOB, parent BLOB,
    diff BLOB,
    other_features BLOB,
    is_damaging INTEGER)

score
    (revid INTEGER PRIMARY KEY,
    is_damaging_actual INTEGER,
    is_damaging_prediction INTEGER,
    score_positive REAL)

STEPS
create_sqlite_tables
export_tsv_to_sqlite
  read from tsv
  insert into observations table; pickle other_features
download_conents
  loop for each revision from observations table
  download content_current, content_parent
  insert into content table
extract_features
  calculate hv for content_current, content_parent and diff
  populate hv features into feature_vector table
copy_other_features_to_features_db
  copy other features from observations table into feature_vector table
build_model(consider_other_features = False)
score_model_iterative

example_predictions
